import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Reshape, BatchNormalization
from tensorflow.keras.optimizers import Adam
from pykalman import KalmanFilter
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from stable_baselines3 import DQN
from torch_geometric.nn import GCNConv
import shap
import torch
import gym

# Function to download stock data
def download_stock_data(ticker):
    try:
        stock_data = yf.download(ticker, start='2018-01-01', end='2023-01-01')
        return stock_data[['Close']]
    except Exception as e:
        print(f"Error downloading data: {e}")
        return None

# Function to apply Kalman Filter
def apply_kalman_filter(data):
    kf = KalmanFilter(initial_state_mean=0, n_dim_obs=1)
    state_means, _ = kf.filter(data['Close'].values)
    data['Kalman_Filtered'] = state_means
    return data

# Function to build the GAN generator model
def build_generator(input_dim):
    model = Sequential()
    model.add(Dense(128, input_dim=input_dim, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dense(256, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dense(512, activation='relu'))
    model.add(Dense(1, activation='linear'))  # Output size is 1
    return model

# Function to build the GAN discriminator model
def build_discriminator(input_shape):
    model = Sequential()
    model.add(Dense(512, input_shape=input_shape, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dense(256, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dense(1, activation='sigmoid'))  # Binary classification
    return model

# Function to build the GAN model
def build_gan(generator, discriminator):
    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])
    discriminator.trainable = False  # Freeze the discriminator while training the generator
    model = Sequential([generator, discriminator])
    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))
    return model

# Function to train the GAN
def train_gan(epochs, batch_size, input_dim, real_data):
    generator = build_generator(input_dim)
    discriminator = build_discriminator((1,))
    gan = build_gan(generator, discriminator)

    for epoch in range(epochs):
        # Create noise
        noise = np.random.normal(0, 1, (batch_size, input_dim))
        generated_data = generator.predict(noise)

        # Labels for the discriminator
        real_labels = np.ones((batch_size, 1))
        fake_labels = np.zeros((batch_size, 1))

        # Train the discriminator
        d_loss_real = discriminator.train_on_batch(real_data, real_labels)
        d_loss_fake = discriminator.train_on_batch(generated_data, fake_labels)

        # Train the GAN
        noise = np.random.normal(0, 1, (batch_size, input_dim))
        gan_labels = np.ones((batch_size, 1))
        g_loss = gan.train_on_batch(noise, gan_labels)

        # Print losses during training
        if epoch % 500 == 0:
            print(f"Epoch: {epoch}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss[0]}")

    return generator

# Function to generate synthetic data
def generate_synthetic_data(generator, n_samples):
    noise = np.random.normal(0, 1, (n_samples, input_dim))
    synthetic_data = generator.predict(noise)
    return synthetic_data

# Class for the Trading Environment
class TradingEnv(gym.Env):
    def __init__(self, stock_data):
        super(TradingEnv, self).__init__()
        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(10,), dtype=np.float32)
        self.action_space = gym.spaces.Discrete(3)  # 3 actions: Sell, Buy, Hold
        self.current_step = 0
        self.data = stock_data['Close'].values

    def reset(self):
        self.current_step = 0
        return self._next_observation()

    def _next_observation(self):
        obs = self.data[self.current_step:self.current_step + 10]  # 10-day price data
        return obs

    def step(self, action):
        self.current_step += 1
        reward = 0  # Reward calculation (e.g., profit or loss)
        done = self.current_step >= len(self.data) - 10
        return self._next_observation(), reward, done, {}

# Function to evaluate the DQN model
def evaluate_model(model, env):
    total_reward = 0
    obs = env.reset()
    done = False
    while not done:
        action = model.predict(obs)[0]  # Get the action predicted by the model
        obs, reward, done, _ = env.step(action)  # Step in the trading environment
        total_reward += reward
    return total_reward

# Function to optimize hyperparameters
def optimize_hyperparameters(env):
    def dqn_performance(lr, gamma):
        model = DQN('MlpPolicy', env, learning_rate=lr, gamma=gamma, verbose=0)
        model.learn(total_timesteps=5000)
        return evaluate_model(model, env)

    optimizer = BayesianOptimization(f=dqn_performance, pbounds={'lr': (1e-5, 1e-2), 'gamma': (0.8, 0.99)})
    optimizer.maximize(init_points=2, n_iter=5)

# Main execution
if __name__ == "__main__":
    # Step 1: Download stock data
    df_stock = download_stock_data(ticker)
    if df_stock is None:
        exit()

    # Step 2: Apply Kalman Filter
    df_stock = apply_kalman_filter(df_stock)

    # Step 3: Train GAN model
    input_dim = 100
    epochs = 10000
    batch_size = 32
    real_data = df_stock['Close'].values.reshape(-1, 1)
    generator = train_gan(epochs, batch_size, input_dim, real_data)

    # Generate synthetic data
    synthetic_data = generate_synthetic_data(generator, 1000)

    # Visualize synthetic data
    plt.figure(figsize=(10, 6))
    plt.plot(synthetic_data, label='Synthetic Data')
    plt.title('Synthetic Stock Price Data Generation')
    plt.xlabel('Observation Number')
    plt.ylabel('Price')
    plt.legend()
    plt.show()

    # Step 4: Create trading environment
    env = TradingEnv(df_stock)

    # Step 5: Train DQN model
    model_dqn = DQN('MlpPolicy', env, verbose=1)
    model_dqn.learn(total_timesteps=10000)

    # Step 6: Optimize hyperparameters
    optimize_hyperparameters(env)

    # Step 7: SHAP for Explainable AI Analysis
    explainer = shap.DeepExplainer(model_dqn.policy, np.random.rand(10, 10))
    shap_values = explainer.shap_values(np.random.rand(10, 10))

    # Visualize SHAP values
    shap.summary_plot(shap_values, np.random.rand(10, 10))

    # Step 8: Real-Time Event Detection and NLP-Based Real-Time Event Analysis
    sentiment_model = AutoModelForSequenceClassification.from_pretrained("cardiffnlp/twitter-roberta-base-sentiment")
    tokenizer = AutoTokenizer.from_pretrained("cardiffnlp/twitter-roberta-base-sentiment")

    # Example tweets for sentiment analysis
    tweets = []  # Populate this list with your actual tweets
    for tweet in tweets:
        inputs = tokenizer(tweet, return_tensors="pt")
        sentiment_scores = sentiment_model(**inputs)
        print(f"Tweet: {tweet} | Sentiment Scores: {sentiment_scores}")

    # Step 9: Portfolio Optimization Using Markowitz Theory
    def markowitz_portfolio(returns, risk_free_rate=0.01):
        mean_returns = returns.mean()
        cov_matrix = returns.cov()
        num_assets = len(mean_returns)
        weights = np.random.random(num_assets)
        weights /= np.sum(weights)  # Normalize weights

        portfolio_return = np.dot(weights, mean_returns)
        portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        return portfolio_return, portfolio_std_dev

    # Example returns (randomly generated)
    returns = pd.DataFrame(np.random.randn(100, 5), columns=['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN'])
    portfolio_return, portfolio_std_dev = markowitz_portfolio(returns)
    print(f"Portfolio Return: {portfolio_return}, Portfolio Risk (Std Dev): {portfolio_std_dev}")

    # Step 10: Visualize Predictions
    plt.figure(figsize=(10, 6))
    plt.plot(df_stock.index, df_stock['Close'], color='blue', label='Real Prices')
    plt.title(f'Stock Price Prediction for {ticker} (Advanced Analysis)')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.legend()
    plt.show()
